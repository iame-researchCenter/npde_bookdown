[["index.html", "npde: Open Source R normalised prediction distribution errors Welcome to the npde package in R User Guide Legalese", " npde: Open Source R normalised prediction distribution errors Emmanuelle Comets, Karl Brendel, Marc Cerou, Thi Huyen Tram Nguyen, Romain Leroux, France Mentré 2021-09-01 Welcome to the npde package in R The \\(\\sf{npde}\\) project is an R package available in CRAN that provides routines to compute normalised prediction distribution errors and normalised prediction discrepancies, which are simulation-based residuals designed to evaluate non-linear mixed effect models such as those used in pharmacokinetics and pharmacodynamics. References concerning the methods include the papers (Brendel et al. 2006), (Emmanuelle Comets, Brendel, and Mentré 2008), (THT Nguyen and Mentré 2012), (Emmanuelle and France 2021). User Guide A comprehensive user guide providing documentation about npde, no longer bundled along with the package because of its size, is now available on the GitHub repository https://github.com/ecomets/npde30/blob/main/userguide_npde_3.1.pdf. Legalese npde is a software distributed under the terms of the GNU GENERAL PUBLIC LICENSE Version 2, June 1991 ( [GPL-2] (https://cran.r-project.org/web/licenses/GPL-2) | [GPL-3] (https://cran.r-project.org/web/licenses/GPL-3) [expanded from: GPL (&gt;=2)]). The terms of this license are in a file called COPYING which you should have received with this software. If you have not received a copy of this file, you can obtain one via the world wide web at http://www.gnu.org/copyleft/gpl.html, or by writing to: The Free Software Foundation, Inc.,51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA. References "],["introduction.html", "1 Introduction 1.1 Contents of the bookdown 1.2 Citing npde", " 1 Introduction 1.1 Contents of the bookdown For details on installing the library, see section 2 Installation. Sections 3 Statistical methods to 4 Diagnostic graphs present the statistical models and methods: in section 3 Statistical methods, we describe the statistical models and the evaluation methods. We also give details on specific methods to handle censored data or the different decorrelation methods available in section 4 Diagnostic graphs, we describe the diagnostic graphs available in the package Section 5 Using the npde package shows a step-by-step example of using the library to produce default diagnostic plots for the theophylline data. In section 6 Examples, we illustrate the use of the package through several examples, showcasing the various diagnostic graphs and their interpretation. In section 7 Types of graphs in the npde library, we show which plot types are available (some depend on whether for instance covariates or data below the limit of quantification are present in the dataset) for a NpdeObject object. The options available for binning are also shown. Section 8 Tayloring options for graphs shows all the arguments that can be passed on to the plot() functions to change layout, titles, colours, symbols, content, in order to personalise the plots. Section 9 Types of graphs in the npde library describes the different kinds of plots that can be produced using the plot.type argument to the generic plot() function, as well as the corresponding specialised functions that are called to produce each type of graph. Finally, section 11 References has a list of relevant references to the publications about npde and other diagnostic tools, while section 10 Structure of the npde package contains some technical details concerning the online help, S4 classes and methods of the package. 1.2 Citing npde If you use this program in a scientific publication, we would like you to cite the following reference: Emmanuelle Comets, Brendel, and Mentré (2008). Additional references are: Brendel et al. (2006), Emmanuelle, Karl, and Mentré (2010), T. H. T. Nguyen, Comets, and Mentré (2012), Emmanuelle Comets, Nguyen, and Mentré (2013), Emmanuelle Comets and Mentré (2021). References "],["installation.html", "2 Installation 2.1 CRAN 2.2 Github: Build from source", " 2 Installation npde can be installed and used on several platforms. The program is distributed as an add-on package (library) for R, and is available on the CRAN, from the menu or using the command install.packages() from within R. Superuser privileges may be required for a system-wide installation. Please consult the R Installation and Administration manual (section 6) provided with R (or available from the CRAN) for further details concerning the installation of packages. 2.1 CRAN You can install the package directly from your R console using the install.packages() command from R: install.packages(&quot;npde&quot;) 2.2 Github: Build from source You can also build it from Github using the R package devtools: library(&quot;devtools&quot;) install_github(&quot;ecomets/npde&quot; ) library(npde) "],["statisticalMethods.html", "3 Statistical methods 3.1 Models and notations 3.2 Computing pde and npde 3.3 Decorrelating the data to obtain \\(\\mathrm{pde}\\) 3.4 Censoring methods 3.5 Tests", " 3 Statistical methods 3.1 Models and notations Let \\(i\\) denote the i\\(^{\\rm th}\\) individual (\\(i\\) = 1,\\(\\dots\\), N) and \\(j\\) the j\\(^{\\rm th}\\) measurement in an individual (\\(j\\) = 1,\\(\\dots\\), n\\(_i\\), where n\\(_i\\) is the number of observations for subject \\(i\\)). Let \\(\\mathrm{Y}_i\\)=\\(\\{y_{i_1},\\dots,y_{i_{n_i}} \\}\\) be the n\\(_i\\)-vector of observations observed in individual \\(i\\). Let the function \\(f\\) denote the nonlinear structural model. \\(f\\) can represent for instance the pharmacokinetic model. The statistical model for the observation \\(y_{ij}\\) in patient \\(i\\) at time \\(t_{ij}\\), is given by: \\[\\begin{equation} y_{ij}=f(t_{ij},\\theta_i)+\\varepsilon_{ij} \\end{equation}\\] where \\(\\theta_i\\) is the p-vector of the individual parameters and \\(\\epsilon_{ij}\\) is the residual error, which is assumed to be normal, with zero mean. The variance of \\(\\varepsilon_{ij}\\) may depend on the predicted concentrations \\(f(t_{ij},\\theta_i)\\) through a (known) variance model. Let \\(\\sigma\\) denote the vector of unknown parameters of this variance model. In pharmacokinetic (PK) \\(\\normalsize{/}\\) pharmacodynamic (PD) studies for instance, it is usually assumed that the variance of the error follows a combined error model: \\[\\begin{equation} \\mathrm{Var}(\\varepsilon_{ij})= (\\sigma_{\\rm inter} + \\sigma_{\\rm slope} f(t_{ij},\\theta_i))^2 \\tag{3.1} \\end{equation}\\] where \\(\\sigma_{\\rm inter}\\) and \\(\\sigma_{\\rm slope}\\) are two parameters characterising the variance. In this case, \\(\\sigma=(\\sigma_{\\rm inter},\\sigma_{\\rm slope})\\). This combined variance model covers the case of an homoscedastic variance error model, where \\(\\sigma_{\\rm slope}=0\\), and the case of a constant coefficient of variation error model when \\(\\sigma_{\\rm inter}=0\\). Another parametrisation often found is: \\[\\begin{equation} \\mathrm{Var}(\\varepsilon_{ij})= \\sigma_{\\rm inter}^2 + \\sigma_{\\rm slope}^2 \\; f(t_{ij},\\theta_i)^2 \\end{equation}\\] Another usual assumption in population PK/PD analyses is that the distribution of the individual parameters \\(\\theta_i\\) has a known shape, for instance the normal, log-normal or logit distribution. Following the model structure laid out in the http://wiki.webpopix.org/index.php/What_is_a_model%3F_A_joint_probability_distribution!, we will assume a transformation \\(h\\) can be used to transform a linear function of the fixed effects \\(\\mu\\), the vector of covariates \\(\\mathrm{X}_i\\) and the random effects \\(\\eta_i\\), into the vector of individual parameters for individual \\(i\\), \\(\\theta_i\\): \\[\\begin{equation} \\theta_i=h(\\mu, X_i \\eta_i) \\tag{3.2} \\end{equation}\\] where the \\(\\eta_i\\) are assumed to follow a normal distribution \\(\\mathcal{N} (0, \\Omega)\\), with \\(\\Omega\\) the variance-covariance matrix of the random effect. Other parametric or non-parametric assumptions can be used for the distribution of the random effects, as in the first paper using this method, in the context of non-parametric estimation (Florence et al. 1998). Although npde were developed in the context of pharmacokinetic and pharmacodynamic analyses, it is a general approach that can be used to evaluate mixed effect models. The key assumption is to be able to simulate from the expected model, and the npde are designed to test whether simulations and observations correspond. We denote \\({\\rm \\Psi}\\) the vector of population parameters (also called hyperparameters) estimated using the data in a learning dataset B: \\({\\rm \\Psi}= (\\mu, \\Omega,\\sigma)^{\\top}\\). We call M\\(^B\\) the model defined by its structure (function \\(f\\), distributions \\(h\\), and variance model) and by the hyperparameters \\(\\widehat{\\rm \\Psi}^B\\) estimated from the learning dataset B. 3.2 Computing pde and npde Let V a validation dataset. Evaluation methods compare the predictions obtained by M\\(^B\\), using the design of V, to the observations in V. V can be the learning dataset B (internal validation) or a different dataset (external validation). The null hypothesis (H\\(_0\\)) is that data in the validation dataset V can be described by model M\\(^B\\). Prediction discrepancies and prediction distribution errors are metrics designed to test this assumption. 3.2.1 Prediction discrepancies (pd) Let p\\(_{i}(y|\\Psi)\\) be the whole marginal posterior predictive distribution of an observation \\(y\\) for the individual predicted by the tested model. p\\(_i\\) is defined as: \\[p_{i}(y|\\Psi)=\\int p(y|\\theta_{i},\\Psi) p(\\theta_{i}|\\Psi)d\\theta_{i}\\] Let \\(F_{ij}\\) denote the cumulative distribution function (cdf) of the predictive distribution p\\(_{i}(y|\\Psi)\\). The prediction discrepancy for an observation is defined as the corresponding value of the cdf, as given by: \\[\\mathrm{pd}_{ij}=F_{ij}(y_{ij})=\\int^{y_{ij}} p_{i}(y|\\Psi)dy=\\int^{y_{ij}}\\int p(y|\\theta_{i},\\Psi)p(\\theta_{i}|\\Psi)d\\theta_{i}dy\\] In NLMEM, \\(F_{ij}\\) has no analytical expression and can be approximated by simulations. Using the design of the validation dataset V, we simulate \\(K\\) datasets \\(\\mathrm{V}^{sim(k)}\\) (\\(k\\)=1,\\(\\dots\\),K) under model M\\(^B\\). Let \\(\\mathrm{Y}_i^{sim(k)}\\) denote the vector of simulated observations for the \\(i^{\\rm th}\\) subject in the \\(k^{\\rm th}\\) simulation. The prediction discrepancy \\(\\mathrm{pd}_{ij}\\) for observation \\(y_{ij}\\) can then be computed from the cdf \\(F_{ij}\\), as: \\[\\begin{equation} \\mathrm{pd}_{ij} = F_{ij}(y_{ij}) \\approx \\frac{1}{K}{\\displaystyle{\\sum_{k=1}^{K}}\\mathbb{1}_{ \\Big\\{y_{ij}^{sim(k)}&lt;y_{ij} \\Big\\}}} \\tag{3.3} \\end{equation}\\] To handle extreme values of the observations (defined as values smaller or larger than all the simulated values y\\(_{ij}^{sim(k)}\\)), we further set: \\[\\begin{equation*} \\mathrm{pd}_{ij} = \\left\\{ \\begin{array}{l r} \\frac{1}{2K} &amp; \\text{if } y_{ij} \\leq y_{ij}^{sim(k)} \\; \\forall \\; k=1,\\ldots,K \\\\ 1-\\frac{1}{2K} &amp; \\text{if } y_{ij} &gt; y_{ij}^{sim(k)} \\; \\forall \\; k=1,\\ldots,K \\\\ \\end{array} \\right. \\end{equation*}\\] Under H\\(_0\\), if \\(K\\) is large enough, prediction discrepancies \\(\\mathrm{pd}\\) follow \\(\\mathcal{U}(0, 1)\\) by construction. This processs is described in the figure below: 3.2.2 Smoothing the distribution The simulation-based computation described above can lead to ties especially at the extremes, that is, different observations may have the same value of \\(\\mathrm{pd}\\) (this occurs particularly often if the number of simulations is small, or the model is quite different from the data). To avoid this issue, we have implemented an option to smooth the distribution: instead of using directly the quantile of the observation within the simulated distribution, as in equation (3.3), we draw the \\(\\mathrm{pd}\\) randomly between this quantile (say \\(k/K\\)) and the one immediately above (\\((k+1)/K\\)). We do this by adding a sample from a uniform distribution over the interval \\(\\left[0,\\frac{1}{K}\\right]\\) to the value defined by the previous equation: \\[\\begin{equation} \\mathrm{pd}_{ij} = u_{ij} + \\frac{1}{K}{\\displaystyle{\\sum_{k=1}^{K}}\\mathbb{1}_{ \\Big\\{y_{ij}^{sim(k)}&lt;y_{ij} \\Big\\}}} \\end{equation}\\] Again, extreme values of the observations are treated separately: \\[\\begin{equation*} \\mathrm{pd}_{ij} \\sim \\left\\{ \\begin{array}{l r} U \\left[ 0,1/K\\right] &amp; \\text{if } y_{ij} \\leq y_{ij}^{sim(k)} \\; \\forall \\; k=1,\\ldots, K \\\\ U[1-1/K,1] &amp; \\text{if } y_{ij} &gt; y_{ij}^{sim(k)} \\; \\forall \\; k=1,\\ldots, K \\\\ \\end{array} \\right. \\end{equation*}\\] 3.2.3 Normalised prediction distribution errors (npde) When multiple observations are available for one subject, typically in population analyses, the \\(\\mathrm{pd}\\) are correlated within each subject, leading to an inflation in the type I error of tests comparing the distribution of the \\(\\mathrm{pd}\\) to their theoretical distribution (France and Escolano (2006)). To correct for this correlation, we compute the mean \\(\\mathbb{E}(\\mathrm{Y}_i)\\) and variance \\(\\mathrm{Var}(\\mathrm{Y}_i)\\) of the \\(K\\) simulations (Brendel et al. (2006)). The mean is approximated by: \\[\\mathbb{E}(\\mathrm{Y}_{i})\\thickapprox\\frac{1}{K}\\overset{K}{\\underset{k=1}{\\sum}}\\mathrm{Y}_{i}^{sim(k)}\\] and the variance-covariance matrix is approximated by: \\[\\mathrm{Var}(\\mathrm{Y}_{i})\\thickapprox \\frac{1}{K}\\overset{K}{\\underset{k=1}{\\sum}}(\\mathrm{Y}_{i}^{sim(k)}-\\mathbb{E}(\\mathrm{Y}_{i}))(\\mathrm{Y}_{i}^{sim(k)}-\\mathbb{E}(\\mathrm{Y}_{i}))^{\\top}\\] Decorrelation is performed simultaneously for simulated data: \\[ \\mathrm{Y}_{i}^{sim(k)*}= \\mathrm{Var}(\\mathrm{Y}_i)^{-1/2} (\\mathrm{Y}_{i}^{sim(k)}-\\mathbb{E}(\\mathrm{Y}_i))\\] and for observed data: \\[ \\mathrm{Y}_{i}^*= \\mathrm{Var}(\\mathrm{Y}_i)^{-1/2} (\\mathrm{Y}_{i}-\\mathbb{E}(\\mathrm{Y}_i))\\] Since we are looking to obtain residuals, different decorrelation options exist to obtain \\(\\mathrm{Var}(\\mathrm{Y}_i)^{-1/2}\\), corresponding to different sets of decorrelated data. In the npde package, we propose 3 options, which will be detailed in the next section 3.3. Decorrelated \\(\\mathrm{pd}\\) are then obtained using the same formula as (3.3) but with the decorrelated data, and we call the resulting variables prediction distribution errors (\\(\\mathrm{pde}\\)): \\[\\begin{equation} \\mathrm{pde}_{ij} = F^*_{ij}(y^*_{ij}) \\end{equation}\\] Under H\\(_0\\), if \\(K\\) is large enough, the distribution of the prediction distribution errors should follow a uniform distribution over the interval [0,1] by construction of the cdf. Normalized prediction distribution errors (\\(\\mathrm{npde}\\)) can then be obtained using the inverse function of the normal cumulative density function implemented in most software: \\[\\begin{equation} \\mathrm{npde}_{ij} = \\Phi^{-1} (\\mathrm{pde}_{ij}) \\end{equation}\\] By construction, if H\\(_0\\) is true, \\(\\mathrm{npde}\\) follow the \\(\\mathcal{N}(0, 1)\\) distribution and are uncorrelated within an individual. The decorrelation step however does not make the \\(\\mathrm{npde}\\) truly independent, since this is only valid for Gaussian variables and here the model nonlinearity makes this only approximately true (Emmanuelle, Karl, and Mentré (2010)). 3.3 Decorrelating the data to obtain \\(\\mathrm{pde}\\) 3.3.1 Decorrelation methods To calculate the matrix \\(Var(\\mathrm{Y}_i)^{-1/2}\\) used for decorrelating data, we can use different methods. The Cholesky decomposition is a standard way to obtain residuals in regression models, and was used in the initial implementation of the npde library. It is computationally simple, numerically stable, and remains the default method. However, as an iterative pivotal algorithm it is sensitive to the ordering of the vector of \\(\\mathrm{Y}_i\\). In PK or PD applications, time imposes a natural order on the vector of longitudinal observations which makes this method very relevant, however this may not be as simple for instance when there are multiple responses. The Cholesky decomposition method is also used in the proc MIXED of SAS, to calculate residuals for correlated data. Let \\(\\mathrm{C}\\) denote the Cholesky root of \\(\\mathrm{Var}(\\mathrm{Y}_i)\\) so that \\[\\mathrm{C}^{\\top}\\mathrm{C} = \\mathrm{Var}(\\mathrm{Y}_i)\\] Then \\(\\mathrm{Var}(\\mathrm{Y}_i)^{-1/2} = (\\mathrm{C}^{\\top})^{-1}\\). Using a Cholesky decomposition is not the only way to define residuals. An alternative which is invariant to re-ordering of the vector of observations is to use the unique square root of the matrix \\(\\mathrm{Var}(\\mathrm{Y}_{i})\\), obtained using an eigenvalue decomposition. The matrix \\(\\mathrm{Var}(\\mathrm{Y}_i)\\) can be factorized as: \\[\\mathrm{Var}(\\mathrm{Y}_{i})= \\mathrm{Q} \\Lambda \\mathrm{Q}^{-1}\\] where Q is the square matrix of the same dimension of \\(Var(\\mathrm{Y}_i)\\), whose i\\(^{\\rm th}\\) column is the eigenvector of \\(\\mathrm{Var}(\\mathrm{Y}_i)\\) and \\(\\Lambda\\) is the diagonal matrix whose diagonal elements are the corresponding eigenvalues. The square root matrix of \\(Var(\\mathrm{Y}_i)\\) is then calculated as: \\[\\mathrm{Var}(\\mathrm{Y}_i)^{1/2} = \\mathrm{Q} \\Lambda^{1/2} \\mathrm{Q}^{-1}\\] and this square root matrix is inverted to calculate the matrix \\(\\mathrm{Var}(\\mathrm{Y}_i)^{-1/2}\\). This method is currently implemented in MONOLIX 4 and NONMEM 7 to calculate weighted residuals (WRES, IWPRES) and npde. However, when calculating the symmetric square root from the eigen value-eigen vector decomposition, we will essentially be defining principle directions determined by the variance-covariance matrix and thus, the decorrelated observations\\(\\normalsize{/}\\)residuals are rotated and no longer correspond to the natural ordering. We have also implemented a third method, combining a Cholesky decomposition with a polar decomposition~. Let \\(\\mathrm{C}\\) denote the Cholesky root of \\(Var(\\mathrm{Y}_i)\\). Using polar decomposition, the matrix \\(\\mathrm{C}\\) can be factorized as: \\(\\mathrm{C} = \\mathrm{U} \\mathrm{H}\\), where U is a unitary matrix and H is a positive-semidefinite Hermitian matrix. The square root matrix of \\(Var(\\mathrm{Y}_i)\\) is then calculated as: \\[\\mathrm{Var}(\\mathrm{Y}_i)^{1/2} = \\mathrm{U}^{\\top} \\mathrm{C}\\] This square root matrix is then inversed to calculate the matrix \\(\\mathrm{Var}(\\mathrm{Y}_i)^{-1/2}\\). 3.3.2 Choosing a decorrelation method The Cholesky method was the only option available in the previous version of the library (npde 1.2) and is implemented as the default method in the current version (npde 2.0). Choosing the decorrelation method is done using the decorr.method=\"\" option, with the following choices: i.decorr.method=\"cholesky\": Cholesky decomposition (pseudo-inverse obtained by the chol function) ii.decorr.method=\"inverse\": Inverse (unique inverse, obtained using the eigen function) iii.decorr.method=\"polar\": polar decomposition (pseudo-inverse obtained by combining the chol function with the svd function) Note The user needs to be aware that sometimes the decorrelation step (regardless of the method chosen to perform it) will induce or mask patterns in the graphs of npde versus time or predictions. When strange patterns are seen, we advise the user to also look at the \\(\\mathrm{pd}\\) graphs, which do not involve the decorrelation step, to ascertain whether these patterns are really due to model misspecification and not an artefact of the decorrelation step, and/or to test different decorrelation methods. 3.4 Censoring methods npde have been extended to censored data below the quantification limit in T. Nguyen, Comets, and Mentré (2012). Additional extensions have been proposed for time-to-event data (right and interval-censored); these new extensions have not yet been integrated within the package and are available on the development github https://github.com/ecomets/npde30. The npde package provides several methods to handle censoring. 3.4.1 Choosing the method to handle BQL data BQL data means that we do not observe \\(y_{ij}\\) directly, but that we know the observation to be below a censoring value. We restrict ourselves to data below the LOQ, although extension to interval-censored data is straightforward. BQL data in the validation dataset can be treated in different ways: removed from the dataset: optioncens.method = \"omit\" imputed to model predictions: population predictions (option cens.method = \"ppred\") or individual predictions (option cens.method = \"ipred\") with the ppred method, population predictions are computed using the simulated datasets. For observation \\(y_{ij}\\), the population prediction is \\(\\mathbb{E}_k \\Big(y^{sim(k)}_{ij}\\Big)\\). with the ipred method, individual predictions for each observation obtained during the estimation process need to be included in the data file as an additional column \\(\\mathrm{pd}\\) and \\(\\mathrm{npde}\\) are computed after replacing observed and simulated data by the imputed values imputed to a fixed value: to LOQ (option cens.method = \"loq\") or to a value chosen by the user (optioncens.method = \"fixed\",loq=LOQ where LOQ is a number) as in the previous method, \\(\\mathrm{pd}\\) and \\(\\mathrm{npde}\\) are computed after replacing observed and simulated data by the imputed values Sometimes the data includes different LOQs (for instance when the dataset pools several studies with different analytical methods). In this case, the program computes the smallest LOQ in the dataset, and this value is used to censor the simulated data (eg, any simulated value in the dataset lower than the LOQ is omitted or replaced using the imputation method chosen). Note that all methods involve some loss of power, all the more important when the fraction of BQL data is large, and thus conclusions must be made with prudence when using these imputation methods. However, simulations show that the cens.method = \"cdf\" is the most suitable (T. Nguyen, Comets, and Mentré (2012)), and that methods imputing directly with a fixed value or with population model predictions have a poor performance. 3.4.2 Imputation of BQL data using the cumulative distribution function For an observation above LOQ ( Limit Of Quantication ), the \\(\\mathrm{pd}\\) is computed as described above, as the quantile of the observation within the predicted distribution. For a BQL observation (left-censored observation) \\(y^{cens}_{ij}\\) of the i\\(^{\\rm th}\\) individual at time \\(t_{ij}\\), we first evaluate its probability of being under LOQ \\(\\mathbb{P}(y_{ij}^{cens} \\leq {\\rm LOQ})\\) using the predictive distribution predicted from the model: \\[\\begin{equation} \\mathbb{P}(y_{ij}^{cens}\\leq\\mbox{LOQ})=F_{ij}(\\mbox{LOQ})=\\frac{1}{K}{\\displaystyle{\\sum_{k=1}^{K}}\\mathbb{1}_{\\bigg\\{y_{ij}^{sim(k)}\\leq\\text{LOQ}\\bigg\\}}} \\end{equation}\\] (these predicted probabilities are stored and returned in the results, see section @ref(npde.methods). Since we only know that the actual observation is below \\(\\text{LOQ}\\), we propose to compute the \\(\\mathrm{pd}\\) for a left-censored observation y\\(_{ij}^{cens}\\), pd\\(_{ij}^{cens}\\), as a random sample from a uniform distribution over the interval \\[\\big[0, \\mathbb{P}\\big(y_{ij}^{(cens)} \\leq {\\rm LOQ}\\big)\\big]\\] To obtain the \\(\\mathrm{npde}\\) however, we first need to also impute observations which are below LOQ. We transform the imputed \\(\\mathrm{pd}\\) back to an imputed observation using the inverse function of the predictive distribution function \\(F_{ij}\\): \\[\\begin{equation} y_{ij}^{cens(new)}=F_{ij}^{-1}(pd_{ij}^{cens}) \\end{equation}\\] Since \\(\\mathrm{pd}\\) are quantiles, this corresponds to finding the quantile immediately after the imputed \\(\\mathrm{pd}_{ij}\\) and setting \\(y_{ij}^{cens(new)}\\) to the value in the simulated distribution \\(F_{ij}\\) corresponding to that quantile (see figure fig:imputation03 for an illustration). The new vector of observations \\(\\mathrm{Y}_{i}^{new}\\) now contains both observed values, for non censored data, and imputed values for censored data. We cannot simply decorrelate the vector of observed data \\(y_{i}\\) using the simulations from the model, because the simulated dataset also contains values that would have been censored and treating them as simulated. We therefore propose to impute these censored data to a value between 0 and \\(\\text{LOQ}\\) using the same method. We impute a pd\\(_{ij}^{sim^{(new)}(k)}\\) for each y\\(_{ij}^{sim(k)}\\) below \\(\\text{LOQ}\\) in the simulated data and these y\\(_{ij}^{sim(k)}\\) are replaced using the same imputation method applied to the observed data. \\[\\begin{equation} y_{ij}^{sim^{(new)}(k)}=F_{ij}^{-1}(pd_{ij}^{sim^{(new)}(k)})\\,\\,\\,\\mbox{if }y_{ij}^{sim}\\leq \\text{LOQ} \\end{equation}\\] As previously, to avoid ties in the \\(\\mathrm{pd}\\) and \\(\\mathrm{npde}\\), we can jitter the imputed \\(\\mathrm{pd}\\) and \\(y\\). Figure @ref{fig:imputation03} shows an illustration for both cases: method ties = TRUE: if \\(F_{ij}(y_{ij}^{sim(k)}) &lt; pd_{ij}^{cens}\\leq F_{ij}(y_{ij}^{sim(k+1)})\\), then \\(y_{ij}^{cens} = y_{ij}^{sim(k+1)}\\) method ties = FALSE: if \\(F_{ij}(y_{ij}^{sim(k)}) &lt; pd_{ij}^{cens}\\leq F_{ij}(y_{ij}^{sim(k+1)})\\), then \\(y_{ij}^{cens}\\) is randomly sampled in a uniform distribution over the interval \\(\\bigg[ y_{ij}^{sim(k)},y_{ij}^{sim(k+1)} \\bigg]\\) After the imputation step, a new vector of observations \\(\\mathrm{Y}_{i}^{(new)}\\) and new simulated data \\(\\mathrm{Y}_{i}^{sim^{(new)}}\\) are obtained. The complete data are then decorrelated using the same technique as described above. Note that the matrix \\(\\mathrm{Var}(\\mathrm{Y}_i)\\) used to decorrelate is computed using the imputed data, while the predictive distribution functions \\(F_{ij}\\) are computed using the original simulated data before the imputation step. 3.5 Tests 3.5.1 Tests on the distribution of npde Under the null hypothesis that model M\\(^B\\) describes adequately the data in the validation dataset, the \\(\\mathrm{npde}\\) follow the \\(\\mathcal{N}(0, 1)\\) distribution. We report the first three central moments of the distribution of the \\(\\mathrm{npde}\\): mean, variance, skewness, as well as the kurtosis, where we define kurtosis as the fourth moment minus 3 so that the kurtosis for \\(\\mathcal{N}(0,1)\\) is 0 (sometimes called excess kurtosis). The expected value of these four variables for the expected \\(\\mathcal{N}(0,1)\\) are respectively: mean = 0, variance = 1, skewness = 0, kurtosis - 3 = 0. The program also reports the standard errors for the mean (SE=\\(\\sigma/\\sqrt{N}\\)) and variance (SE=\\(\\sigma\\;\\sqrt{2/(N-1)}\\)). We use 3 tests to test the assumption that the \\(\\mathrm{npde}\\) follow the \\(\\mathcal{N}(0, 1)\\) distribution: a Wilcoxon signed rank test, to test whether the mean is significantly different from 0, a Fisher test for variance, to test whether the variance is significantly different from 1, a Shapiro-Wilks test, to test whether the distribution is significantly different from a normal distribution. The package also reports a global test, which consists in considering the 3 tests above with a Bonferroni correction (Brendel et al. (2010)). The p-value for this global test is then reported as the minimum of the 3 p-values multiplied by 3, the number of simultaneous tests (or 1 if this value is larger than 1) (Wright (1992)). A graphical code is used in the library to highlight significant results, similar to the code used by other statistical functions in R such as lm (see example). The normality test is very powerful, especially with large amount of observations. When the test remains significant even after model refinement, QQ-plots should be used to assess model adequacy in addition to the 3 statistical tests. This is especially useful in large datasets where the sheer amount of data will lead to reject even reasonable models. 3.5.2 Tests for covariate models In Brendel et al. (2010), we proposed two approaches to evaluate a model with or without covariates with a validation dataset. In the first approach, for continuous covariates we can test for correlations between the covariate and \\(\\mathrm{npde}\\), using the Spearman correlation test; for categorical covariates we can use Wilcoxon or Kruskal-Wallis tests. If the model and validation data correspond, there should be no relationship between \\(\\mathrm{npde}\\) and covariates. In the second approach, we proposed to split the \\(\\mathrm{npde}\\) according to the values of the covariate, and test within each category that \\(\\mathrm{npde}\\) follows a \\(\\mathcal{N}(0,1)\\) distribution. For categorical covariates, \\(\\mathrm{npde}\\) are split by categories of the covariate. We proposed to discretise continuous covariates in 3 classes, below first quartile (\\(&lt;\\)Q\\(_1\\)), between first and third quartiles (Q\\(_1\\)Q\\(_3\\)) and above third quartile (\\(&gt;\\)Q\\(_3\\)). If the model and validation data correspond, there should be no significant departure from \\(\\mathcal{N}(0,1)\\) within each category: a test is performed for each category, and the resulting p-values are corrected with a Bonferroni correction. Both approaches gave similar results in terms of type I error in a simulation study, but the second approach has a slightly larger type I error and a correspondingly slight increase in power (Brendel et al. (2010)). Tests for covariate models will be added shortly to the library. References "],["graphmethods.html", "4 Diagnostic graphs 4.1 Assessing the distribution of npde 4.2 VPC 4.3 Probability of being under the LOQ 4.4 Graph features 4.5 Graphs for covariate models 4.6 Graphs with a reference profile", " 4 Diagnostic graphs Diagnostic graphs aim to assess the goodness-of-fit between the model and the dataset and to determine whether the underlying model assumptions seem appropriate (T. Nguyen et al. (2017)). The npde package provides diagnostics for npd and npde, as well as diagnostics such as VPC. 4.1 Assessing the distribution of npde Graphs can be used to visualise the shape of the distribution of the \\(\\mathrm{npde}\\). Classical plots include quantile-quantile plots (QQ-plots) of the distribution of the \\(\\mathrm{npde}\\) against the theoretical distribution, as well as histograms and empirical cumulative distributions of the \\(\\mathrm{npde}\\) and \\(\\mathrm{pd}\\). We also find that scatterplots of the \\(\\mathrm{npde}\\) versus the independent variable, the predicted dependent variables, or covariates, can help pinpoint model deficiencies. Some of these graphs are plotted by default (see section 6). The package computes for each observation the predicted value as the empirical mean over the \\(k\\) simulations of the simulated predicted distribution (denoted \\(\\mathbb{E}_k\\big(y^{sim(k)}_{ij}\\big)\\)), which is reported under the name \\(\\mathrm{ypred}\\) along with the \\(\\mathrm{npde}\\) and\\(\\normalsize{/}\\)or \\(\\mathrm{pd}\\). In the field of population PK\\(\\normalsize{/}\\)PD, graphs of residuals versus predictions use the values predicted by the model even when the residuals have been decorrelated, as is the case for both spe and npde here. Comparing metrics to their theoretical distributions can be done through QQ-plots or histograms (Goujard et al. (2010)). Examples of these different graphs will be shown in the next section. 4.2 VPC Visual Predictive Check (VPC) are standard diagnostic graphs that are now available also in the npde library. In contrast to \\(\\mathrm{npde}\\), they do not handle heterogeneity in the design (eg dose regimen) or covariates, so that they are most useful in balanced designs to evaluate models without covariates. However since they are directly obtained from model observations and predictions they illustrate very nicely the shape of the evolution of independent versus dependent variable. VPC are obtained by simulating repeatedly under the model and plotting selected percentiles of the simulated data, comparing them to the same percentiles in the observed data. By default, the VPC produced in the npde package correspond to the median and limits of the 95% prediction interval (eg, the 2.5th, 50th and 97.5th percentile of the data). The observed data can also be plotted over the interval, or omitted for very large datasets. In the presence of censored data, the same imputation method is also applied to the VPC. For instance, with the default method cens.method='cdf', the data under the LOQ is set to the value imputed from the predictive distribution through the imputed \\(\\mathrm{pde}\\), as described in methods, forcens.method='ipred' it it replaced by the corresponding individual predictions (which then have to be given in the dataset), while for cens.method='omit', it is removed from the dataset. In this last case, the simulated data used to compute the prediction bands is also removed from the simulated dataset, yielding larger prediction bands reflecting the lower number of observations involved. 4.3 Probability of being under the LOQ When the dataset includes data below the LOQ, a plot of the probability of being BQL can be useful to assess whether the model is able to adequately predict low values, and is available in the npde package. 4.4 Graph features 4.4.1 Stratification When the model contains covariate effects, traditional VPC should be stratified and examined in each group. Alternatively, corrections such as pcVPC have been proposed, but are not implemented in the npde library. All the graphs available in the npde library can be stratified by levels of categorical covariates to determine whether trends appear in certain groups. For continuous covariates, categories can be created by grouping covariates into quantiles to achieve the same result (Brendel et al. (2010)). 4.4.2 Prediction intervals In the current version of the library, prediction bands around selected percentiles, which can be obtained through repeated simulations under the model being tested, can be added to most graphs to highlight departures from predicted values (Emmanuelle, Karl, and Mentré (2010)). Prediction intervals build on the idea of simulating from the model to evaluate whether it can reproduce the observed data. For the VPC, a 95% prediction interval on a given percentile (eg the median) can be obtained by computing the median for the K simulated datasets and taking the region where 95% of these K medians lie. This can also be applied to scatterplots of \\(\\mathrm{npde}\\) or \\(\\mathrm{pd}\\), where for each percentile plotted in the graph we can compute a prediction interval of a given size. By default, 95% is used in the npde, and each prediction interval is plotted as a coloured area (blue for the 2.5 and 97.5\\(^{\\rm th}\\) percentile and pink for the median); the corresponding 2.5\\(^{\\rm th}\\), 50\\(^{\\rm th}\\) and 97.5\\(^{\\rm th}\\) percentiles of the observed data are plotted as lines or points, and should remain within the coloured areas. A binning algorithm is used for the prediction intervals (the number of bins can be adjusted by the user). Different options are: equal bin sizes on the X-axis equal bin widths on the X-axis optimal binning using a clustering algorithm to select the optimal breaks; user-selected breaks. The binning algorithm uses the Mclust library (C. Fraley and Raftery (2002),C. Fraley and Raftery (2006)) for R, which implements model-based clustering with an EM-algorithm to select the optimal number of clusters for the variable on the X-axis of the graph. 4.5 Graphs for covariate models Two types of diagnostic graphs are available in the npde library for covariates. First, all the graphs can be split according to the values of the covariate, to examine the \\(\\mathrm{npde}\\) separately in each group. We use the representation proposed in (Brendel et al. (2010)) to evaluate covariate models, where \\(\\mathrm{npde}\\) are split by category for discrete covariates or by quantiles for continuous covariates (by default, 3 quantiles are used, \\(&lt;Q1\\), interquartile range \\(Q1-Q3\\) over the middle 50% value of the covariate, and \\(&gt;Q3\\), but the user can select the number of pertinent categories relative to the problem at hand). Prediction bands are also added to those graphs. A second type of diagnostic is to plot the \\(\\mathrm{npde}\\) or \\(\\mathrm{npd}\\) versus covariates, to examine the trends. For continuous covariates, a scatterplot of the metrics versus the covariate is provided, while for categorical covariates, we show boxplots for the different categories. 4.6 Graphs with a reference profile A new feature of the npde library is the ability to add a reference plot to the scatterplot of \\(\\mathrm{npde}\\) or \\(\\mathrm{npd}\\) versus the independent variable. This was first described in a poster at the PAGE conference (E. Comets, Nguyen, and Mentré (2013)), and makes the \\(\\mathrm{npde}\\) plots similar in aspect to VPC, with information on both the evolution of the process and the distribution of residuals in the same plot. The principle is to first select a reference profile, which can be associated with a subject or a group of subject, a covariate or combination of covariates. We then distribute the \\(\\mathrm{npde}\\) (or the \\(\\mathrm{npd}\\)) around this reference profile, taking into account the interindividual variability. To do this, we first compute for each value \\(x_t\\) of the predictor \\(x\\) the mean \\(\\mathbb{E}_{t_{ij}}\\) and standard deviation SD\\(_{t_{ij}}\\) of the simulations corresponding to the selected reference profile for that time. Denoting \\(I_R\\) the set of individuals corresponding to the reference profile, we compute: \\[\\begin{equation} \\begin{split} \\mathbb{E}_{t_{ij}} &amp;= \\frac{1}{I_R \\; K} \\sum_{k=1}^{K} \\sum_{i \\in I_R} y_{ij}^{sim(k)} \\\\ {\\rm Var}_{t_{ij}} &amp;= \\frac{1}{I_R \\; K -1} \\sum_{k=1}^{K} \\sum_{i \\in I_R} (y_{ij}^{sim(k)} - \\mathbb{E}_{t_{ij}})^2 \\\\ \\end{split} \\end{equation}\\] We then compute the transformed \\(\\mathrm{npde}\\) at time \\(t_{ij}\\) as: \\[\\begin{equation} \\mathrm{tnpde}_{ij} = \\mathbb{E}_{t_{ij}} + {\\rm SD}_{t_{ij}} \\; \\mathrm{npde}_{ij} \\end{equation}\\] This is performed for each time point for a balanced design. In the case of an unbalanced design, we first bin the predictors on the \\(X\\) axis (M. Lavielle and Bleakley (2011)) and we compute the mean and SD for each bin, which are used within each bin to compute the transformed \\(\\mathrm{npde}\\). If the reference profile doesnt cover all the bins, we interpolate the missing values from the means and SD estimated in the available bins. We then produce plots of \\(\\mathrm{tnpde}\\) versus the predictor as previously, for a given interval size (eg 90% prediction intervals), by computing the observed and simulated percentiles of the \\(\\mathrm{tnpde}\\) on the observed and simulated data respectively. Prediction intervals around the percentiles can be obtained by the same transformation. Finally, we can apply the same procedure to transform the \\(\\mathrm{npd}_{ij}\\), bearing in mind the \\(\\mathrm{tnpde}_{ij}\\) will retain the correlation due to repeated observations. The plots generated with a reference profile have a similar interpretation as VPC, but since they are based on \\(\\mathrm{npde}\\), there should be no correlation between the different \\(\\mathrm{tnpde}\\) for a subject. A minor difference in construction is that VPC plot the median and extreme percentiles (eg 5\\(^{\\rm th}\\) and 95\\(^{\\rm th}\\) percentiles for a 90% VPC), while with \\(\\mathrm{tnpde}\\) we translate the median of the residual plots by the mean of the reference profile, and expand the extreme percentiles using the standard deviation. Note that it is the users responsibility to use a pertinent reference profile. For example, if the design contains different dose-groups, the reference profile should be computed across one of the doses. In addition, the npde library offers an option to set a different reference profile for each value of a covariate when splitting the scatterplot over covariates (see previous section). 4.6.1 Non-parametric construction of \\(\\mathrm{tnpde}\\) An alternative using the median and quantiles of the reference profile to transform the \\(\\mathrm{npde}\\) will be implemented shortly. References "],["npdePackage.html", "5 Using the npde package 5.1 Theophylline data 5.2 Preparation of the input 5.3 Execution 5.4 Results", " 5 Using the npde package In this section, we describe in details how to use the npde package, using the theophylline data. Other examples are shown in section 6. Some additional datasets are packaged, others are available in the subdirectory doc/inst of the library and/or on the github https://github.com/ecomets/npde30/tree/main/keep/data 5.1 Theophylline data 5.2 Preparation of the input The library needs two files: the file containing the dataset to be evaluated (hereafter named observed data) the file containing the simulations (hereafter named simulated data) The library does not perform the simulations. R, NONMEM (Beal et al. (1989-2011)), MONOLIX (Marc Lavielle (2005)) or any program of your choice can be used for that purpose. 5.2.1 Observed data The observed data file must contain at least the following 3 columns: id: patient identification xobs: independent variable (time, X, ) yobs: dependent variable (DV, concentrations, effects) Additional (optional) columns may be given. The program will recognise the following input: cens: censoring information (0 for observed data, 1 for censored data) mdv: missing data (0 for observed data, 1 for missing data); this information supersedes censoring information, so that an observation with mdv equal to 1 will be treated as missing, not as censored; observations with values . or NA will also be considered as missing ipred: individual model predictions covariates The computation of and will remove missing observations from the observed dataset reported in the output (see section results). Other columns may be present but will not be used by the library. The actual order of the columns is unimportant, since the user may specify which column contain the requested information, but the default order is 1. id, 2. xobs, 3. yobs and no MDV column. A file header may be present, and column separators should be one of: blank space(s), tabulation mark, comma (,) or semi-colon (;). Finally, the digit mark should be a dot as in English (eg a number would read 4.5) and not a comma as in French (4,5). To run the theophylline example, we load the data through the data() function, and show the first lines: data(theopp) head(theopp) ## ID Dose Time Conc Wt ## 1 1 4.02 0.00 NA 79.6 ## 2 1 NA 0.25 2.84 NA ## 3 1 NA 0.57 6.57 NA ## 4 1 NA 1.12 10.50 NA ## 5 1 NA 2.02 9.66 NA ## 6 1 NA 3.82 8.58 NA Here, the first column contains the patient ID, while the third and fourth contain respectively the independent and the dependent variables. 5.2.2 Simulated data The user must provide a file containing the K simulated datasets stacked one after the other. Within each simulated dataset, the order of the observations must be the same as within the observed dataset. The dimensions of the two datasets must be compatible: if n\\(_{\\rm obs}\\) is the number of lines in the observed dataset, the file containing the simulated datasets must have K\\(\\times\\)n\\(_{\\rm obs}\\) lines. The simulated data file must contain at least 3 columns, in the following order: id : patient identification xsim: independent variable (time, X, ) ysim: dependent variable (DV, concentrations, effects) Additional columns may be present but will not be used by the library. The length of the \\(\\color{purple}{id}\\) (resp \\(\\color{purple}{xobs}\\)) column must be equal to the length of the \\(\\color{purple}{id}\\) (resp \\(\\color{purple}{xobs}\\)) column of the observed dataset repeated K times. The simtheopp dataset is distributed along with the package, so we can load it as previously using data(). data(simtheopp) head(simtheopp) ## ID xsim ysim ## 1 1 0.00 -0.090212 ## 2 1 0.25 2.289200 ## 3 1 0.57 4.227900 ## 4 1 1.12 5.497900 ## 5 1 2.02 7.917300 ## 6 1 3.82 5.394300 We can check that the 3 first columns provide the right information in the right order (id, simulated independent variable, simulated dependent variable). 5.2.3 Number of simulations Based on the results of simulation studies (Brendel et al. (2010),Emmanuelle, Karl, and Mentré (2010)), we recommend to use at least \\(K\\)=1000 but the actual number may depend on the dataset involved, and should be increased when the dataset includes a large number of subjects. This will be investigated in more details in future work on npde. A warning will be issued when \\(K\\) is smaller than 1000. Note that because of size constraints on CRAN, the dataset simtheopp we are using in this section only contains 100 replicates of the original dataset, lower than the 1000+ recommended to compute npde. 5.3 Execution 5.3.1 Interactive execution The interactive mode is called by the function npde(): myres&lt;-npde() 5.3.1.1 Using npde() The user will be prompted to enter successively: the name of the file or dataframe containing the observed data (here, theopp) the columns in which id, xobs, dependent variable yobs, and possibly column with missing data MDV can be found (the default order is 1, 2, 3 and no MDV column, therefore here we change ix and iy to reflect the structure of theopp) the name of the file or dataframe containing the simulated data (here, simtheopp) whether results should be saved to disk; if so, the user must also enter the format of the graph (one of: Postscript, JPEG, PNG or PDF) the name of the files: an extension npde will be added to this name for the file in which numerical results are to be saved (see section results), and an extension depending on the format of the graph will be added to this name for the file in which graphs are to be saved (respectively .eps, .jpeg, .png, .pdf for the formats above). For instance, if the user enters myoutput and requests that the graphs be saved in PDF format, the results file will be named myoutput.npde and the graph files will be myoutput.pdf. whether \\(\\mathrm{npde}\\) should be computed whether \\(\\mathrm{pd}\\) should be computed whether a message should be printed as the computation of \\(\\mathrm{npde}\\) begins in a new subject whether the function should return values (see section value) Alternatively, one or both filenames for the observed and simulated data can be replaced by a dataframe if the data has already been loaded in R (see example in the online documentation provided with the package). 5.3.1.2 Application to the theophylline example The interactive version of the program was run below for the theophylline example. In a first step, the user was prompted to enter all details necessary for the computations \\(\\color{purple}{ \\textbf{in purple}}\\) show values entered by the user while text in black is printed by the program: myres&lt;-npde() Name of the file containing the observed data: \\(\\color{purple}{\\textbf{theopp.tab}}\\) Automatic recognition of columns in the dataset (y\\(\\normalsize{/}\\)Y) [default=yes] ? \\(\\color{purple}{\\textbf{n}}\\) Im assuming file theopp.tab has the following structure: ID X Y \\(\\dots\\) and does not contain a column signaling missing data. To keep, press ENTER, to change, type any letter: \\(\\color{purple}{\\textbf{n}}\\) Column with ID information ? \\(\\color{purple}{\\textbf{1}}\\) Column with X (eg time) information ? \\(\\color{purple}{\\textbf{3}}\\) Column with Y (eg DV) information ? \\(\\color{purple}{\\textbf{4}}\\) Column signaling missing data (eg MDV, press ENTER if none) ? Column signaling censoring (eg CENS, press ENTER if none) ? Column with individual predictions (eg ipred, press ENTER if none) ? Columns with covariates (eg WT; enter one at a time, press ENTER if none or when finished) ? Name of the file containing the simulated data: \\(\\color{purple}{\\textbf{ simtheopp.tab}}\\) Do you want results and graphs to be saved to files (y\\(\\normalsize{/}\\)Y) [default=yes] ? \\(\\color{purple}{\\textbf{y}}\\) Different formats of graphs are possible: Postscript (extension eps) JPEG (extension jpeg) PNG (extension png) Acrobat PDF (extension pdf) Which format would you like for the graph (1-4) ? \\(\\color{purple}{\\textbf{1}}\\) Name of the file (extension will be added, default=output): \\(\\color{purple}{\\textbf{theophylline}}\\) Do you want to compute npde (y\\(\\normalsize{/}\\)Y) [default=yes] ? \\(\\color{purple}{\\textbf{y}}\\) Do you want to compute pd (y\\(\\normalsize{/}\\)Y) [default=yes] ? \\(\\color{purple}{\\textbf{y}}\\) Different decorrelation methods are available: Cholesky decomposition (default) Inverse using diagonalisation (as in Monolix and Nonmem) Cholesky followed by polar decomposition Which method should be used for the decorrelation (1-3) ? \\(\\color{purple}{\\textbf{1}}\\) Method used to handle censored observations: omit: pd will be set to NaN for missing data cdf: pd will be imputed using a random sample from \\(\\mathcal{U}\\big[0,p_{\\text{LOQ}}\\big]\\) where \\(p_{\\text{LOQ}}\\) is the probability, according to the model, that a given observation is less than LOQ (default) loq: an observation below the LOQ will be imputed to the LOQ ypred: an observation below the LOQ will be imputed to the population model prediction ipred: an observation below the LOQ will be imputed to the individual model prediction Which method should be used (1-5) ? \\(\\color{purple}{\\textbf{2}}\\) Do you want a message printed as the computation of npde begins in a new subject (y\\(\\normalsize{/}\\)Y) [default=no] ? \\(\\color{purple}{\\textbf{y}}\\) Do you want the function to return an object (y\\(\\normalsize{/}\\)Y) [default=yes] ? \\(\\color{purple}{\\textbf{y}}\\) In the second step, the program computed the normalised prediction distribution errors, plotted the corresponding graphs and performed the statistical tests for npde, then computed the prediction discrepancies (for which no tests are reported). A warning is issued here because the number of simulations is considered too small. Here we see that the test of the mean (t-test) and variance (Fisher variance test) dont shown any significant departure from the theoretical values of 0 and 1 respectively, on the other hand, the normality test (SW test of normality) indicates a departure from the normal distribution, so that the global test (Global adjusted p-value), consisting of a Bonferroni-corrected combination of the three test, also shows a significant departure from the theoretical distribution. However, the results of the tests dont necessarily reflect model adequacy in this case, because of the small number of simulations used. Automatic detection of variables is ON. The program will attempt to detect both mandatory variables (ID, X, Y) and optional variables (IPRED, MDV, CENS) when they are not specifically given or when the user-specified names are not found in the dataset, by looking in the names of the columns (to override this behaviour, please use argument detect=FALSE in the call to npdeData(). Reading data from file ../data/theopp.tab These are the first lines of the dataset as read into R. Please check the format of the data is appropriate, if not, modify the na and/or sep items and retry: ID Dose Time Conc Wt 1 1 4.02 0.00 NA 79.6 2 1 NA 0.25 2.84 NA 3 1 NA 0.57 6.57 NA 4 1 NA 1.12 10.50 NA 5 1 NA 2.02 9.66 NA 6 1 NA 3.82 8.58 NA The following NpdeData object was successfully created: Object of class NpdeData longitudinal data Dataset ../data/theopp.tab Structured data: Conc ~ Time | ID predictor: Time (hr) NpdeDataReading data from file ../data/simtheopp.tab These are the first lines of the dataset as read into R. Please check the format of the data is appropriate, if not, modify the na and/or sep items and retry: ID xsim ysim 1 1 0.00 -0.090212 2 1 0.25 2.289200 3 1 0.57 4.227900 4 1 1.12 5.497900 5 1 2.02 7.917300 6 1 3.82 5.394300 There are rows with MDV=1 in the original dataset, the corresponding rows will be removed from the simulated dataset. Warning: the number of simulations is 100 which may be too small. We advise performing at least 1000 simulations to compute npde. Computing the npde for subject 1 Computing the npde for subject 2 Computing the npde for subject 3 Computing the npde for subject 4 Computing the npde for subject 5 Computing the npde for subject 6 Computing the npde for subject 7 Computing the npde for subject 8 Computing the npde for subject 9 Computing the npde for subject 10 Computing the npde for subject 11 Computing the npde for subject 12 --------------------------------------------- Distribution of npde : nb of obs: 120 mean= 0.0668 (SE= 0.095 ) variance= 1.074 (SE= 0.14 ) skewness= 0.511 kurtosis= 0.2912 --------------------------------------------- Statistical tests (adjusted p-values): t-test : 1 Fisher variance test : 1 SW test of normality : 0.00819 ** Global test : 0.00819 ** --- Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 --------------------------------------------- 5.3.2 Non-interactive execution In the non-interactive mode, the required information is fed to the function autonpde instead of answering a series of questions. The minimum input should include the name of the observed data file (for example, theopp.tab) and the name of the simulated data file (for example, simtheopp.tab, as in: autonpde(&quot;theopp.tab&quot;,&quot;simtheopp.tab&quot;) 5.3.2.1 Application to the theophylline example Here is an example of the call to autonpde() with the theophylline data: y&lt;-autonpde(namobs=theopp,namsim=simtheopp,iid=1,ix=3,iy=4, imdv=0,namsav=&quot;output.eps&quot;,boolsave=T,type.graph=&quot;eps&quot;,verbose=T) ## Using the object called theopp in this R session as the data. ## ## ## The following NpdeData object was successfully created: ## ## Object of class NpdeData ## longitudinal data ## Structured data: Conc ~ Time | ID ## predictor: Time () ## Using the object called simtheopp in this R session as the data. ## There are rows with MDV=1 in the original dataset, the corresponding rows will be removed from the simulated dataset. ## Warning: the number of simulations is100which may be too small. ## We advise performing at least 1000 simulations to compute npde. ## Computing the npde for subject 1 ## Computing the npde for subject 2 ## Computing the npde for subject 3 ## Computing the npde for subject 4 ## Computing the npde for subject 5 ## Computing the npde for subject 6 ## Computing the npde for subject 7 ## Computing the npde for subject 8 ## Computing the npde for subject 9 ## Computing the npde for subject 10 ## Computing the npde for subject 11 ## Computing the npde for subject 12 ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 120 ## mean= 0.0668 (SE= 0.095 ) ## variance= 1.074 (SE= 0.14 ) ## skewness= 0.511 ## kurtosis= 0.2912 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 1 ## Fisher variance test : 1 ## SW test of normality : 0.00819 ** ## Global test : 0.00819 ** ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- ## Saving results in file output.eps.npde ## Saving graphs in file output.eps.eps ## Transparency options not working with ggsave, please use cairo to save the plot in eps format or choose another output format (pdf, png, jpeg). ## Selected plot type: default ## Method used for binning: by quantiles on X , dividing into the following 10 intervals ## Interval Centered.On Nb.obs ## 1 (-0.75,0.418] 0.28 12 ## 2 (0.418,0.854] 0.57 12 ## 3 (0.854,1.48] 1.03 12 ## 4 (1.48,2.76] 2.02 12 ## 5 (2.76,4.41] 3.56 12 ## 6 (4.41,6.1] 5.04 12 ## 7 (6.1,8.09] 7.05 12 ## 8 (8.09,10.7] 9.06 12 ## 9 (10.7,19.5] 12.03 12 ## 10 (19.5,24.6] 24.20 12 ## Method used for binning: by quantiles on X , dividing into the following 10 intervals ## Interval Centered.On Nb.obs ## 1 (-0.11,2.05] 1.4 12 ## 2 (2.05,3.56] 3.2 12 ## 3 (3.56,4.29] 4.0 12 ## 4 (4.29,5.07] 4.8 12 ## 5 (5.07,5.57] 5.3 12 ## 6 (5.57,6.25] 5.9 12 ## 7 (6.25,6.95] 6.6 12 ## 8 (6.95,7.47] 7.2 12 ## 9 (7.47,8.22] 7.8 12 ## 10 (8.22,10] 9.0 12 Theinvisible() option is used to suppress the output when it is not affected to an object. A number of options can also be set as arguments, and are given in table  5.4 Results Both execution modes will produce the same results. Three types of results are produced by default, but options can be used so that only some of them are created: an R object of class NpdeObject, containing several elements, including the \\(\\mathrm{npde}\\) and/or \\(\\mathrm{pd}\\) (see section {sec:value}). With the option output=F the object is not returned. a graph file containing diagnostic plots of the \\(\\mathrm{npde}\\) (output.eps with the default values; see section {sec:graphics}). The graph also appears in the graphic window of the current R session. With the option boolsave=F the graph is shown but not saved to a file. a text file with the same name as the graph file and extension .npde containing the following data ( output.npde with the default values), organised in columns: id, xobs, ypred, npde, pd With the option boolsave=F, the results are not saved. 5.4.1 Value By default, the function returns an object of class NpdeObject: print(y) The npde package uses the S4 class system, and many functions have been defined to handle the object and produce descriptive summaries and plots (please refer to section sec:npde.methods for more details about S4 classes). As a result, the output is no longer a list that can be manipulated, but a slightly more complicated object. A summary function can be used to produce a list containing the main results: x1&lt;-summary(y) The object returned by the function contains 5 elements: : a NpdeData object containing the information relative to the observed data : a NpdeSimData object containing the information relative to the simulated data : a NpdeRes object containing the results : a list of options used in the computations : a list of graphical preferences The first three elements are S4 objects also, with their own class and own methods, while the last two elements are R lists. More information on how to handle these objects and which methods have been defined for them can be found in {sec:npde.methods}. 5.4.2 Tests The package automatically outputs the results of the statistical tests comparing the distribution of the npde to the theoretical distribution N(0,1). These tests can be obtained using the method gof.test() applied to the object: gof.test(y) 5.4.2.1 Application to the theophylline example This yields the following output for theophylline: --------------------------------------------- Distribution of npde : nb of obs: 120 mean= 0.0668 (SE= 0.095 ) variance= 1.074 (SE= 0.14 ) skewness= 0.511 kurtosis= 0.2912 --------------------------------------------- Statistical tests (adjusted p-values): t-test : 1 Fisher variance test : 1 SW test of normality : 0.00819 ** Global test : 0.00819 ** --- Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 --------------------------------------------- Here, the four p-values are redirected to the R object y. With the option which=pd (resp. pd), the user can select tests for the \\(\\mathrm{pd}\\) (resp. \\(\\mathrm{npd}\\)) instead of the \\(\\mathrm{npde}\\), but the tests will only be strictly valid when there is only one observation per subject, otherwise the test incurrs a significant increase in type I error (Mentré and Escolano (2006), Brendel et al. (2006)). 5.4.2.2 gof.test method A gof.test() method has also been defined for numeric vectors, in which case it will compute the first moments and perform the four tests. The statistical diagnostics can therefore be regenerated easily without running the computation all over again, provided the results have been saved. In the example above, the \\(\\mathrm{npde}\\) were saved to a file named theophylline.npde. The following code reads the results from this file and computes the same tests as above: dat&lt;-read.table(&quot;theophylline.npde&quot;,header=T) y&lt;-gof.test(dat$npde) 5.4.3 Default graphs Important change from previous version following the white paper by the ISoP group (T. Nguyen et al. (2017)), the default plots now produced by the npde package use npd instead of npde, while the npde are used as default for the statistical tests. Four graphs are produced by default: a quantile-quantile plot: plot of the \\(\\mathrm{npd}\\) versus the corresponding quantiles of a normal distribution the line \\(y=x\\) is also drawn a histogram of the \\(\\mathrm{npd}\\) the shape of the normal distribution \\(\\mathcal{N}(0,1)\\) is also shown a plot of the \\(\\mathrm{npd}\\) versus the independent variable X a plot of the \\(\\mathrm{npd}\\) versus ypred for these last two graphs, we plot the lines corresponding to \\(y=0\\) and to the critical values 5% and 95% (delimiting the 90% confidence interval in which we expect to find the bulk of the \\(\\mathrm{npde}\\)). The default graphs now include (approximated) prediction intervals (obtained by simulating from the theoretical \\(\\mathcal{N}(0,1)\\) distribution, see section {sec:graphmethods}); for compatibility with the behaviour of version 1.2, the option bands=FALSE can be used to suppress plotting the prediction intervals. These graphs are designed as diagnostics for the \\(\\mathrm{npd}\\) and the \\(\\mathrm{npde}\\); a function providing similar graphs for \\(\\mathrm{pd}\\), for which the reference distribution is uniform instead of normal, is plotpd. 5.4.3.1 Plots for the theophylline example The graphs below are plotted in a window ## Selected plot type: default ## Method used for binning: by quantiles on X , dividing into the following 10 intervals ## Interval Centered.On Nb.obs ## 1 (-0.75,0.418] 0.28 12 ## 2 (0.418,0.854] 0.57 12 ## 3 (0.854,1.48] 1.03 12 ## 4 (1.48,2.76] 2.02 12 ## 5 (2.76,4.41] 3.56 12 ## 6 (4.41,6.1] 5.04 12 ## 7 (6.1,8.09] 7.05 12 ## 8 (8.09,10.7] 9.06 12 ## 9 (10.7,19.5] 12.03 12 ## 10 (19.5,24.6] 24.20 12 ## Method used for binning: by quantiles on X , dividing into the following 10 intervals ## Interval Centered.On Nb.obs ## 1 (-0.11,2.05] 1.4 12 ## 2 (2.05,3.56] 3.2 12 ## 3 (3.56,4.29] 4.0 12 ## 4 (4.29,5.07] 4.8 12 ## 5 (5.07,5.57] 5.3 12 ## 6 (5.57,6.25] 5.9 12 ## 7 (6.25,6.95] 6.6 12 ## 8 (6.95,7.47] 7.2 12 ## 9 (7.47,8.22] 7.8 12 ## 10 (8.22,10] 9.0 12 The quantile-quantile plot and the histogram show a group of values corresponding to \\(\\mathrm{npde}=2.33\\), corresponding to predicted distribution errors set at 0.99, and the prediction bands shows the corresponding departure graphically on the two upper graphs. This indicates observations larger than all the 100 corresponding simulated values. This often happens when \\(K\\) is small as is the case in this example (K=100), and can explain the departure from normality seen in the tests. However, even increasing the number of simulations to 1000 or 2000 does not in this example yield a non-significant test, meaning the model does not describe the data adequately (results not shown). In the scatterplots (lower two graphs), the pink area is the prediction interval for the median, while the blue areas shows the prediction areas for the boundaries of the 95% prediction intervals. The prediction bands are very large because of the small number of simulations so that model misspecification is not so obvious. By default, the binning on the X-axis uses bins of equal size (number of observations), and the mean of the X values in the bin is used to plot the bin, which explains why the bins do not extend to the largest X-value especially in the lower right plot, but this default behaviour can be tuned in the options. The graph below shows the VPC, where the prediction bands are again very large because of the low number of simulations. ## Selected plot type: vpc ## Plotting VPC ## Method used for binning: by quantiles on X , dividing into the following 10 intervals ## Interval Centered.On Nb.obs ## 1 (-0.75,0.418] 0.28 12 ## 2 (0.418,0.854] 0.57 12 ## 3 (0.854,1.48] 1.03 12 ## 4 (1.48,2.76] 2.02 12 ## 5 (2.76,4.41] 3.56 12 ## 6 (4.41,6.1] 5.04 12 ## 7 (6.1,8.09] 7.05 12 ## 8 (8.09,10.7] 9.06 12 ## 9 (10.7,19.5] 12.03 12 ## 10 (19.5,24.6] 24.20 12 References "],["examples.html", "6 Examples 6.1 Load the libraries and the npde package 6.2 Load the data and the simulated data 6.3 Compute the normalised prediction distribution errors 6.4 Data 6.5 Covariate model 6.6 Reference profile 6.7 Computing npde in the presence of BQL data", " 6 Examples 6.1 Load the libraries and the npde package # Libraries library( gridExtra ) library( ggplot2 ) library( grid ) library( devtools ) library( mclust ) library( npde ) 6.2 Load the data and the simulated data Github repository for the data https://github.com/ecomets/npde30/tree/main/keep/data # Data data( warfarin ) data( simwarfarinCov ) fullDatDir = paste0(getwd(),&quot;/data/&quot;) simwarfarinBase = read.table( file.path( fullDatDir, &quot;simwarfarinBase.tab&quot; ), header = TRUE ) 6.2.1 Warfarin : description of the data # Warfarin head( warfarin ) ## id time amt dv dvid wt sex age ## 1 100 0.5 100 0.0 1 66.7 1 50 ## 2 100 1.0 100 1.9 1 66.7 1 50 ## 3 100 2.0 100 3.3 1 66.7 1 50 ## 4 100 3.0 100 6.6 1 66.7 1 50 ## 5 100 6.0 100 9.1 1 66.7 1 50 ## 6 100 9.0 100 10.8 1 66.7 1 50 # Warfarin with base model head( simwarfarinBase ) ## id xsim ysim ## 1 100 0.5 -0.08832318 ## 2 100 1.0 0.35687036 ## 3 100 2.0 6.36276558 ## 4 100 3.0 8.88972144 ## 5 100 6.0 11.90216904 ## 6 100 9.0 11.93056720 # Warfarin with covariate model head( simwarfarinCov ) ## id xsim ysim ## 1 100 0.5 -0.07684729 ## 2 100 1.0 0.48476881 ## 3 100 2.0 6.86641424 ## 4 100 3.0 11.54095368 ## 5 100 6.0 11.59647752 ## 6 100 9.0 10.04260881 6.3 Compute the normalised prediction distribution errors wbase &lt;- autonpde( namobs = warfarin, namsim = simwarfarinBase, iid = 1, ix = 2, iy = 4, icov = c( 3,6:8 ), namsav = &quot;warfBase&quot;, units = list( x = &quot;hr&quot;, y = &quot;ug/L&quot;, covariates = c( &quot;mg&quot;,&quot;kg&quot;,&quot;-&quot;,&quot;yr&quot; ) ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 247 ## mean= 0.03419 (SE= 0.06 ) ## variance= 0.8753 (SE= 0.079 ) ## skewness= -0.1149 ## kurtosis= -0.0497 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 1 ## Fisher variance test : 0.471 ## SW test of normality : 1 ## Global test : 0.471 ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- wcov &lt;- autonpde( namobs = warfarin, namsim = simwarfarinCov, iid = 1, ix = 2, iy = 4, icov = c( 3,6:8 ), namsav = &quot;warfCov&quot;, units = list( x = &quot;h&quot;, y = &quot;mg/L&quot;, covariates = c( &quot;mg&quot;,&quot;kg&quot;,&quot;-&quot;,&quot;yr&quot; ) ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 247 ## mean= 0.02928 (SE= 0.059 ) ## variance= 0.8549 (SE= 0.077 ) ## skewness= -0.07211 ## kurtosis= -0.4172 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 1 ## Fisher variance test : 0.288 ## SW test of normality : 1 ## Global test : 0.288 ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- show( wbase ) ## Object of class NpdeObject ## ----------------------------------------- ## ---- Component data ---- ## ----------------------------------------- ## Object of class NpdeData ## Structured data: dv ~ time | id ## Covariates: amt wt sex age ## This object has the following components: ## data: data ## with 32 subjects ## 247 observations ## The data has the following components ## X: time (hr) ## Y: dv (ug/L) ## missing data: mdv (1=missing) ## ----------------------------------------- ## ---- Component results ---- ## ----------------------------------------- ## Object of class NpdeRes ## containing the following elements: ## predictions (ypred) ## prediction discrepancies (pd) ## normalised prediction distribution errors (npde) ## completed responses (ycomp) for censored data ## decorrelated responses (ydobs) ## the dataframe has 247 non-missing observations . ## First 10 lines of results, removing missing observations: ## ypred ycomp pd ydobs npde ## 1 0.5814627 0.0 0.359 -0.43862113 -0.3611330 ## 2 3.1220995 1.9 0.454 -0.05116685 0.1636585 ## 3 8.4386880 3.3 0.126 -1.35607837 -1.4985131 ## 4 11.2936700 6.6 0.140 0.04661369 0.1560419 ## 5 12.6249280 9.1 0.127 -0.56691520 -0.5417366 ## 6 11.7504645 10.8 0.355 0.89677342 0.9230138 ## 7 10.8386881 8.6 0.141 -1.08057832 -1.1358962 ## 8 8.5881834 5.6 0.026 -1.89143682 -1.8521799 ## 9 7.0369975 4.0 0.019 -1.06275059 -1.0278933 ## 10 5.7174611 2.7 0.017 -0.60300349 -0.5947658 print( wbase ) ## Object of class NpdeObject ## ----------------------------------- ## ---- Data ---- ## ----------------------------------- ## Object of class NpdeData ## longitudinal data ## Structured data: dv ~ time | id ## predictor: time (hr) ## covariates: amt (mg), wt (kg), sex (-), age (yr) ## Dataset characteristics: ## number of subjects: 32 ## number of non-missing observations: 247 ## average/min/max nb obs: 7.72 / 6 / 13 ## First 10 lines of data: ## index id time dv amt wt sex age mdv ## 1 1 100 0.5 0.0 100 66.7 1 50 0 ## 2 1 100 1.0 1.9 100 66.7 1 50 0 ## 3 1 100 2.0 3.3 100 66.7 1 50 0 ## 4 1 100 3.0 6.6 100 66.7 1 50 0 ## 5 1 100 6.0 9.1 100 66.7 1 50 0 ## 6 1 100 9.0 10.8 100 66.7 1 50 0 ## 7 1 100 12.0 8.6 100 66.7 1 50 0 ## 8 1 100 24.0 5.6 100 66.7 1 50 0 ## 9 1 100 36.0 4.0 100 66.7 1 50 0 ## 10 1 100 48.0 2.7 100 66.7 1 50 0 ## ## Summary of original data: ## vector of predictor time ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.50 24.00 48.00 50.76 72.00 120.00 ## vector of response dv ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 3.200 6.000 6.346 8.850 17.600 ## ----------------------------------- ## ---- Key options ---- ## ----------------------------------- ## Methods ## compute normalised prediction discrepancies (npd): yes ## compute normalised prediction distribution errors (npde): yes ## method for decorrelation: Cholesky decomposition (upper triangular) ## method to treat censored data: Impute pd* and compute y* as F-1(pd*) ## Input/output ## verbose (prints a message for each new subject): FALSE ## save the results to a file, save graphs: TRUE ## type of graph (eps=postscript, pdf=adobe PDF, jpeg, png): eps ## file where results should be saved: warfBase.npde ## file where graphs should be saved: warfBase.eps ## ----------------------------------- ## ---- Results ---- ## ----------------------------------- ## Object of class NpdeRes ## resulting from a call to npde or autonpde ## containing the following elements: ## predictions (ypred) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4257 3.1100 6.1058 6.3002 8.5267 16.8707 ## prediction discrepancies (pd) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0030 0.3115 0.5670 0.5344 0.7615 0.9995 ## normalised prediction distribution errors (npde) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -2.29037 -0.57258 0.05768 0.03419 0.71437 2.87816 ## completed responses (ycomp) for censored data ## decorrelated responses (ydobs) ## the dataframe has 247 non-missing observations . summary( wbase ) ## Object of class NpdeObject containing the following main components ## data: data ## N= 32 subjects ## ntot.obs= 247 non-missing observations ## subject id: id ## predictor (X): time ## response (Y): dv ## covariates: amt wt sex age ## sim.data: simulated data: ## number of replications: nrep= 1000 ## results: results of the computation ## ypred: individual predictions (E_i(f(theta_i,x))) ## pd: prediction discrepancies ## npde: normalised prediction distribution errors ## ycomp: imputed responses for censored data ## ploq: probability of being &lt;LOQ for each observation ## options: options for computations ## prefs: options for graphs 6.3.1 Description of the output wcov # wcov head( wcov ) ## Object of class NpdeData ## Structured data: dv ~ time | id ## Covariates: amt wt sex age ## This object has the following components: ## data: data ## with 32 subjects ## 247 observations ## The data has the following components ## X: time (h) ## Y: dv (mg/L) ## missing data: mdv (1=missing) # wcov slots slotNames( wcov ) ## [1] &quot;data&quot; &quot;results&quot; &quot;sim.data&quot; &quot;options&quot; &quot;prefs&quot; # wcov covariates wcov@data@name.covariates ## [1] &quot;amt&quot; &quot;wt&quot; &quot;sex&quot; &quot;age&quot; # wcov graphical options #wcov@prefs 6.4 Data 6.4.1 Plot the data for the base model plot.type = \"data\" : Plots the observed data in the dataset # wbase model plot( wbase, plot.type = &quot;data&quot; ) 6.4.2 Default plot for the base model # base model plot( wbase, which = &quot;npde&quot; ) plot.type = \"hist\" Histogram plot.type = qqplot QQ-plot of the npde versus its theoretical distribution plot.type = x.scatter Scatterplot of the npde versus the predictor plot.type = pred.scatter Scatterplot of the npde versus the population predicted values hist = plot( wbase, plot.type = &quot;hist&quot;, which = &quot;npde&quot; ) qqplot = plot( wbase, plot.type = &quot;qqplot&quot;, which = &quot;npde&quot; ) x_scatter = plot( wbase, plot.type = &quot;x.scatter&quot;, which = &quot;npde&quot; ) pred_scatter = plot( wbase, plot.type = &quot;pred.scatter&quot;, which = &quot;npde&quot; ) grid.arrange( grobs = list( hist, qqplot ), nrow = 1, ncol = 2 ) grid.arrange( grobs = list( x_scatter, pred_scatter ), nrow = 1, ncol = 2 ) 6.5 Covariate model 6.5.1 Default plots # covariate model plot( wcov , which = &quot;npde&quot;) 6.5.2 Scatterplots of npd plot.type = \"x.scatter\" : Scatterplot of the npd versus the predictor covsplit = TRUE : split by categories # Splitting npde vs time plots by covariates plot( wcov, plot.type = &quot;x.scatter&quot;, covsplit = TRUE, which.cov = c( &quot;wt&quot; ) ) # plot( wcov, plot.type = &quot;x.scatter&quot;, covsplit = TRUE, which.cov = c( &quot;wt&quot;,&quot;sex&quot; ) ) # plot( wcov, plot.type = &quot;x.scatter&quot;, covsplit = TRUE, which.cov = c( &quot;wt&quot; ), which = &quot;pd&quot; ) # plot( wcov, plot.type = &quot;x.scatter&quot;, covsplit = TRUE, which.cov = c( &quot;wt&quot; ), which = &quot;npde&quot; ) 6.5.3 Plot npd as boxplots for each covariate category plot.type = \"covariates\" npd represented as boxplots for each covariate category wt.covariate.boxplot &lt;- plot( wcov, plot.type = &quot;covariates&quot;, which.cov = c( &quot;wt&quot; ) ) sex.covariate.boxplot &lt;- plot( wcov, plot.type = &quot;covariates&quot;, which.cov = c( &quot;sex&quot; ) ) # grid plot grid.arrange( grobs = list( wt.covariate.boxplot[[1]], sex.covariate.boxplot[[1]] ), nrow = 1, ncol = 2 ) 6.5.4 Diagnostic plots for covariates plot.type = \"cov.scatter\" : Scatterplot of the npd versus covariates plot.type = \"covariates\" : Boxplots for each covariate category plot.type = \"ecdf\" : Empirical distribution function # cov.scatter xwt.covscatt &lt;- plot( wcov, plot.type = &quot;cov.scatter&quot;, which.cov = &quot;wt&quot;, bin.method = &quot;optimal&quot; ) # ecdf xwt.ecdf &lt;- plot( wcov, plot.type = &quot;ecdf&quot;, covsplit = TRUE, which.cov = &quot;wt&quot; ) # x.scatter xsex.covscatt &lt;- plot( wcov, plot.type = &quot;x.scatter&quot;, covsplit = TRUE, which.cov = &quot;sex&quot; ) # ecdf xsex.ecdf &lt;- plot( wcov, plot.type = &quot;ecdf&quot;, covsplit = TRUE, which.cov = &quot;sex&quot; ) # grid plot grid.arrange( grobs = list( xwt.covscatt, xwt.ecdf, xsex.covscatt, xsex.ecdf ), nrow = 2, ncol = 2 ) 6.6 Reference profile 6.6.1 Reference plot using one subject plot.tnpde &lt;- plot( wcov, plot.type = &quot;x.scatter&quot;, ref.prof = list( id = 2 ), main = &quot;tnpd with reference profile ID = 2&quot; ) plot.vpc &lt;- plot( wcov, plot.type = &quot;vpc&quot;, main = &quot;VPC&quot; ) grid.arrange( grobs = list( plot.tnpde, plot.vpc ), nrow = 1, ncol = 2 ) 6.6.2 Reference plot using all subjects plot.tnpde &lt;- plot( wcov, plot.type = &quot;x.scatter&quot;, ref.prof = &quot;all&quot;, main = &quot;tnpd&quot;, ylim = c ( 0,20 ) ) plot.vpc &lt;- plot( wcov, plot.type = &quot;vpc&quot;, main = &quot;VPC&quot;, ylim = c( 0, 20 ) ) grid.arrange( grobs = list( plot.tnpde, plot.vpc ), nrow = 1, ncol = 2 ) 6.7 Computing npde in the presence of BQL data data( virload ) data( virload20 ) data( virload50 ) virload &lt;- read.table( file.path( fullDatDir, &quot;virload.tab&quot; ), header = TRUE ) simvirload &lt;- read.table( file.path( fullDatDir, &quot;simvirload.tab&quot; ), header = TRUE ) 6.7.0.1 Censoring methods cens.method = \"omit\" cens.method = \"ipred\" cens.method = \"ppred\" cens.method = \"cdf\" x50 &lt;- autonpde( virload50, simvirload, iid = 1, ix = 2, iy = 3, icens = 4, boolsave = FALSE, units = list( x = &quot;hr&quot;, y = &quot;cp/mL, log 10 base&quot; ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 300 ## mean= -0.06291 (SE= 0.057 ) ## variance= 0.9616 (SE= 0.079 ) ## skewness= 0.1431 ## kurtosis= -0.1453 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 0.802 ## Fisher variance test : 1 ## SW test of normality : 1 ## Global test : 0.802 ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- x50.ipred &lt;- autonpde( virload50, simvirload, iid = 1, ix = 2, iy = 3, icens = 4, iipred = 5, boolsave = FALSE, cens.method = &quot;ipred&quot;, units = list( x = &quot;hr&quot;, y = &quot;cp/mL, log 10 base&quot; ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 300 ## mean= 0.02887 (SE= 0.063 ) ## variance= 1.185 (SE= 0.097 ) ## skewness= 0.04312 ## kurtosis= -0.1197 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 1 ## Fisher variance test : 0.0924 . ## SW test of normality : 1 ## Global test : 0.0924 . ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- x50.ppred &lt;- autonpde( virload50, simvirload, iid = 1, ix = 2, iy = 3, icens = 4, boolsave = FALSE, cens.method = &quot;ppred&quot;, units = list(x = &quot;hr&quot;, y = &quot;cp/mL, log 10 base&quot; ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 300 ## mean= 0.02581 (SE= 0.058 ) ## variance= 0.9968 (SE= 0.082 ) ## skewness= -0.05015 ## kurtosis= 0.8068 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 1 ## Fisher variance test : 1 ## SW test of normality : 0.00144 ** ## Global test : 0.00144 ** ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- x50.omit &lt;- autonpde( virload50, simvirload, iid = 1, ix = 2, iy = 3, icens = 4, boolsave = FALSE, cens.method = &quot;omit&quot;, units = list( x = &quot;hr&quot;, y = &quot;cp/mL, log 10 base&quot; ) ) ## --------------------------------------------- ## Distribution of npde : ## nb of obs: 169 ## mean= 0.1417 (SE= 0.07 ) ## variance= 0.8307 (SE= 0.091 ) ## skewness= -0.05682 ## kurtosis= -0.3378 ## --------------------------------------------- ## Statistical tests (adjusted p-values): ## t-test : 0.135 ## Fisher variance test : 0.321 ## SW test of normality : 1 ## Global test : 0.135 ## --- ## Signif. codes: &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 ## --------------------------------------------- 6.7.1 Data impute.loq : the imputed values are plotted for data under the LOQ line.loq : horizontal line should is plotted at Y=LOQ in data and VPC plots plot.loq : data under the LOQ are plotted x50@data@loq ## [1] 1.7 x1 &lt;- plot( x50, plot.type = &quot;data&quot;, xlab = &quot;Time (hr)&quot;, ylab = &quot;log(Viral load) (cp/mL)&quot;, line.loq = TRUE, ylim = c(0,6.5), main = &quot;LOQ imputed using cdf&quot; ) x2 &lt;- plot( x50, plot.type = &quot;data&quot;, xlab = &quot;Time (hr)&quot;, ylab = &quot;log(Viral load) (cp/mL)&quot;, plot.loq = FALSE, line.loq = TRUE, ylim = c(0,6.5), main = &quot;LOQ removed from plot&quot; ) x3 &lt;- plot( x50, plot.type = &quot;data&quot;, xlab = &quot;Time (hr)&quot;, ylab = &quot;log(Viral load) (cp/mL)&quot;, impute.loq = FALSE, line.loq = TRUE, ylim = c(0,6.5), main = &quot;LOQ as in dataset before imputation&quot; ) x4 &lt;- plot( x50.ipred, plot.type = &quot;data&quot;, xlab = &quot;Time (hr)&quot;, ylab = &quot;log(Viral load) (cp/mL)&quot;, line.loq = TRUE, ylim = c(0,6.5), main = &quot;LOQ imputed to individual prediction&quot; ) grid.arrange( grobs = list(x1,x2,x3,x4 ), nrow = 2, ncol = 2 ) 6.7.2 Comparing the censoring methods 6.7.2.1 Default graphs for the virload50 dataset, default censoring method cdf 6.7.2.2 Default graphs for the virload50 dataset, censoring method omit 6.7.2.3 Default graphs for the virload50 dataset, censoring method ipred 6.7.2.4 Default graphs for the virload50 dataset, censoring method ppred 6.7.3 VPC plots vpc.cdf = plot( x50,plot.type = &quot;vpc&quot;, line.loq=TRUE ) vpc.omit = plot( x50.omit,plot.type = &quot;vpc&quot; ) grid.arrange( grobs = list( vpc.omit, vpc.cdf ), nrow=1, ncol=2) 6.7.4 Scatterplots xscatter.omit &lt;- plot( x50.omit, plot.type = &quot;x.scatter&quot; ) xscatter.cdf &lt;- plot( x50, plot.type = &quot;x.scatter&quot; ) grid.arrange( grobs = list( xscatter.omit, xscatter.cdf ), nrow = 1, ncol = 2 ) plot(x50 , plot.type = &quot;x.scatter&quot;, plot.box = TRUE ) 6.7.5 Plot for \\(\\mathbb{P}(Y&lt;LOQ)\\) # P(Y&lt;LOQ) plot( x50, plot.type = &quot;loq&quot;, main = &quot; &quot;) "],["graphTypes0.html", "7 Types of graphs in the npde library 7.1 Plot type 7.2 Specific plot functions", " 7 Types of graphs in the npde library 7.1 Plot type The plot.type argument can be used to control the type of plot needed. The following table shows the available plot types: Plot type Description data Plots the observed data in the dataset x.scatter Scatterplot of the versus the predictor X (optionally can plot or instead) pred.scatter Scatterplot of the versus the population predicted values cov.scatter Scatterplot of the versus covariates covariates represented as boxplots for each covariate category vpc Plots a Visual Predictive Check loq Plots the probability for an observation to be BQL, versus the predictor X ecdf Empirical distribution function of the (optionally or ) hist Histogram of the (optionally or ) qqplot QQ-plot of the versus its theoretical distribution (optionally or ) cov.x.scatter Scatterplot of the versus the predictor X (optionally can plot or instead), split by covariate category cov.pred.scatter Scatterplot of the versus the population predicted values, split by covariate category cov.hist Histogram of the , split by covariate category cov.ecdf Empirical distribution function of the , split by covariate category cov.qqplot QQ-plot of the , split by covariate category \\[tab:plot.type\\] By default these graphs are produced for npd, but the which argument can be used to change that behaviour. For instance, the following code will show scatterplots of npde versus the independent covariate: plot(myres, plot.type=&quot;x.scatter&quot;, which=&quot;npde&quot;) 7.1.0.1 Application to theophylline Data: 7.2 Specific plot functions All the plot types above can also be accessed through their individual plot functions, given in the last column of the table above. Individual help functions are available to detail how to use each function. 7.2.1 Binning Most graphs now have the option of adding prediction intervals. These prediction intervals are computed using simulations under the model, and they require a binning algorithm. The influence of the number and position of bins is quite important for the visual assessment of the fit. Several options are available for binning, and can be set using the vpc.method option. Possible options are: equal: uses quantiles of the data to have about the same number of points in each bin width: divides the interval into bins of equal size user: user-defined breakpoints, set in vpc.breaks (will automatically be expanded to include the lower and upper value of the data if not provided) (if vpc.breaks is not supplied, the equal method will be used instead) optimal: uses the Mclust function from the mclust library (when available) to provide the optimal clustering; the Mclust method With all methods, if the number of bins requested is larger than the number of unique values of X, the number of bins will be limited to the number of unique values. Warning When using the optimal method, warnings may appear. The optimal number of bins is selected from a range equal to vpc.bin \\(\\pm 5\\), but a message such as:In map(out$z) : no assignment to usually indicates that the number of bins is too large, it is then advised to change the value of vpc.bin and start again. Specifying c(0.01,0.99) with the equal or width binning method and vpc.bin=10 will create 2 extreme bands containing 1% of the data on the X-interval, then divide the region within the two bands into the remaining 8 intervals each containing the same number of data; in this case the intervals will all be equal except for the two extreme intervals, the size of which is fixed by the user; complete fine-tuning can be obtained by setting the breaks with the vpc.method=user "],["graphOptions.html", "8 Tayloring options for graphs 8.1 Setting options for graphs 8.2 Layout, titles and axes 8.3 Parameters controlling content. 8.4 Graphical options for VPC and residual plots. 8.5 Colours, transparency, line types and symbols.", " 8 Tayloring options for graphs 8.1 Setting options for graphs An object x resulting from a call to npde() or autonpde() contains a slot prefs where the graphical preferences are stored as a list. Options can be set on the fly for a given plot, by simply adding them to the call to plot() as an argument (see examples in section {sec:npde.examples}), and they will then supersede the preferences attached to the object: plot(x,plot.type=&quot;data&quot;,col=&quot;red&quot;,main=&quot;Raw data&quot;) The options can also be modified directly in the object, and they will then apply to the next plots, for instance changing the new default color to red for all plots is done by setting the attribute col in the list: x[&quot;prefs&quot;]$col&lt;-&quot;red&quot; Options given on the fly will always supersede the options stored in the prefs slot. If further tweaking is required, any graph can also be recreated with a bit of work using the output from the package. Using the function summary will extract the necessary elements from the object, and the user can then use those to produce her or his own graphs. x1&lt;-summary(x) names(x1) head(x1$x) head(x1$npde) 8.2 Layout, titles and axes Argument Default value verbose Output is produced for some plots (most notably when binning is used, this prints out the boundaries of the binning intervals) if TRUE FALSE main Title depends on plot sub Subtitle empty size.main Size of the main title 14 size.sub Size of the title for covariate 12 xlab Label for the X-axis depends on plot ylab Label for the Y-axis depends on plot size.xlab Size of the label for the X-axis 12 size.ylab Size of the label for the Y-axis 12 breaks.x Number of tick marks on the X-axis 10 breaks.y Number of tick marks on the Y-axis 10 size.x.text Size of tick marks and tick labels on the X-axis 10 size.y.text Size of tick marks and tick labels on the Y-axis 10 xlim Range of values on the X-axis empty, adjusts to the data ylim Range of values on the Y-axis empty, adjusts to the data xaxt A character whether to plot the X axis. Specifying \"n\" suppresses plotting of the axis \"y\" yaxt A character whether to plot the Y axis. Specifying \"n\" suppresses plotting of the axis \"y\" xlog Scale for the X-axis (TRUE: logarithmic scale) FALSE ylog Scale for the Y-axis (TRUE: logarithmic scale) FALSE grid If TRUE, display a grid on the background of the plot FALSE 8.3 Parameters controlling content. Argument Default value plot.obs If TRUE, observations, pd/ndpe should are plotted on top of the prediction bands TRUE plot.box If TRUE, boxplots are produced instead of scatterplots FALSE covsplit If TRUE, plot are split by covariates FALSE plot.loq If TRUE, data under the LOQ are plotted TRUE line.loq If TRUE, horizontal line should is plotted at Y=LOQ in data and VPC plots FALSE impute.loq If TRUE, the imputed values are plotted for data under the LOQ TRUE 8.4 Graphical options for VPC and residual plots. Default value bands Whether prediction intervals should be plotted TRUE approx.pi If TRUE, samples from \\(\\mathcal{N}(0,1)\\) are used to plot prediction intervals, while if FALSE, prediction bands are obtained using pd/npde computed for the simulated data TRUE bin.method Method used to bin points (one of \"equal\", \"width\", \"user\" or \"optimal\"); at least the first two letters of the method need to be specified \"equal\" bin.number Number of binning intervals 10 vpc.interval Size of interval 0.95 bin.breaks Vector of breaks used with user-defined breaks (vpc.method=\"user\") NULL bin.extreme Can be set to a vector of 2 values to fine-tune the behaviour of the binning algorithm at the boundaries; specifying c(0.01,0.99) with the \"equal\" binning method and vpc.bin=10 will create 2 extreme bands containing 1% of the data on the X-interval, then divide the region within the two bands into the remaining 8 intervals each containing the same number of data; in this case the intervals will all be equal except for the two extreme intervals, the size of which is fixed by the user; complete fine-tuning can be obtained by setting the breaks with the vpc.method=\"user\" NULL pi.size Width of the prediction interval on the quantiles 0.95 bin.lambda Value of lambda used to select the optimal number of bins through a penalised criterion 0.3 bin.beta Value of beta used to compute the variance-based criterion (Jopt,beta(I)) in the clustering algorithm 0.2 bands.rep Number of simulated datasets used to compute prediction bands 200 8.5 Colours, transparency, line types and symbols. Argument Default value col Main colour for observed data (applied to lines and symbols pertaining to observations if no other option is given to supersede this value) \"slategray4\" lty Line type for observed data 1 lwd Line width for observed data 0.5 pch Symbol used to plot observed data 20 alpha Transparencyfor observed data 1 size Symbol size to plot observed data 1 fill Colour used to fill area elements related to observed data (such as histogram bars) \"white\" type Type for the line for qqplot and scatter. Display line and points. \"b\" col.pobs Colour for observed data \"slategray4\" pch.pobs Symbol used to plot observed data 20 size.pobs Symbol size to plot observed data 1.5 alpha.pobs Transparency for observed data col.lobs Colour for the line of observed data \"slategray4\" lty.lobs Line type for the line of observed data 1 lwd.lobs Line width for the line of observed data 0.5 col.pcens Colour for the censored data \"steelblue3\" pch.pcens Symbol for the censored data 8 size.pcens Symbol size for the censored data 0.6 alpha.pcens Transparency for the censored data 1 col.line.loq Colour for the LOQ line \"black\" lty.line.loq Symbol type for the LOQ line 5 lwd.line.loq Symbol size for the LOQ line 0.5 fill.outliers.med Color for the outliers of the median confidence interval \"red\" fill.outliers.bands Color for the outliers of the bounds of the confidence interval \"red\" alpha.outliers.med Transparency of the color for the outliers of the median confidence interval 1 alpha.outliers.bands Transparency of the color for the outliers the bounds of the confidence interval 1 col.bands Colour for the lines of the bounds of the confidence interval \"white\" lty.bands Type for the lines of bounds of the confidence interval 2 lwd.bands Width of the lines of bounds of the confidence interval 0.25 alpha.bands Transparency of the bounds of the confidence interval 0.3 fill.bands Colour of the confidence interval \"steelblue2\" col.med Colour for the lines of the median of the confidence interval \"white\" lty.med Type for the lines of the median of the confidence interval 2 lwd.med Width of the lines of the median of the confidence interva 0.5 alpha.med Transparency of the median confidence interval 0.5 fill.med Colour of the median confidence interval \"pink\" col.ther Colour for the lines for model-derived percentiles lty.ther Type for the lines for model-derived percentiles 2 lwd.ther Width of the lines for model-derived percentiles 0.5 alpha.ther Transparency of the lines for model-derived percentiles 0.6 "],["graphTypes.html", "9 Types of graphs in the npde library 9.1 Plot type 9.2 Specific plot functions", " 9 Types of graphs in the npde library 9.1 Plot type The plot.type argument can be used to control the type of plot needed. The following table shows the available plot types: Plot type Description data Plots the observed data in the dataset x.scatter Scatterplot of the versus the predictor X (optionally can plot or instead) pred.scatter Scatterplot of the versus the population predicted values cov.scatter Scatterplot of the versus covariates covariates represented as boxplots for each covariate category vpc Plots a Visual Predictive Check loq Plots the probability for an observation to be BQL, versus the predictor X ecdf Empirical distribution function of the (optionally or ) hist Histogram of the (optionally or ) qqplot QQ-plot of the versus its theoretical distribution (optionally or ) cov.x.scatter Scatterplot of the versus the predictor X (optionally can plot or instead), split by covariate category cov.pred.scatter Scatterplot of the versus the population predicted values, split by covariate category cov.hist Histogram of the , split by covariate category cov.ecdf Empirical distribution function of the , split by covariate category cov.qqplot QQ-plot of the , split by covariate category \\[tab:plot.type\\] By default these graphs are produced for npd, but the which argument can be used to change that behaviour. For instance, the following code will show scatterplots of npde versus the independent covariate: plot(myres, plot.type=&quot;x.scatter&quot;, which=&quot;npde&quot;) 9.1.0.1 Application to theophylline Data: plot( y, plot.type = &quot;data&quot; ) ## Selected plot type: data ## Warning: Removed 12 rows containing missing values (geom_point). ## Warning: Removed 12 row(s) containing missing values (geom_path). 9.2 Specific plot functions All the plot types above can also be accessed through their individual plot functions, given in the last column of the table above. Individual help functions are available to detail how to use each function. 9.2.1 Binning Most graphs now have the option of adding prediction intervals. These prediction intervals are computed using simulations under the model, and they require a binning algorithm. The influence of the number and position of bins is quite important for the visual assessment of the fit. Several options are available for binning, and can be set using the vpc.method option. Possible options are: equal: uses quantiles of the data to have about the same number of points in each bin width: divides the interval into bins of equal size user: user-defined breakpoints, set in vpc.breaks (will automatically be expanded to include the lower and upper value of the data if not provided) (if vpc.breaks is not supplied, the equal method will be used instead) optimal: uses the Mclust function from the mclust library (when available) to provide the optimal clustering; the Mclust method With all methods, if the number of bins requested is larger than the number of unique values of X, the number of bins will be limited to the number of unique values. Warning When using the optimal method, warnings may appear. The optimal number of bins is selected from a range equal to vpc.bin \\(\\pm 5\\), but a message such as:In map(out$z) : no assignment to usually indicates that the number of bins is too large, it is then advised to change the value of vpc.bin and start again. Specifying c(0.01,0.99) with the equal or width binning method and vpc.bin=10 will create 2 extreme bands containing 1% of the data on the X-interval, then divide the region within the two bands into the remaining 8 intervals each containing the same number of data; in this case the intervals will all be equal except for the two extreme intervals, the size of which is fixed by the user; complete fine-tuning can be obtained by setting the breaks with the vpc.method=user "],["packageStructure.html", "10 Structure of the npde package 10.1 Errors during execution 10.2 Functions in the npde package", " 10 Structure of the npde package 10.0.1 Online help Details on the functions, available graphs and options can be found in the online documentation. Please type: ?npde.plot.default to get started. 10.1 Errors during execution Sometimes the function is unable to compute the decorrelated prediction distribution errors for one or more subjects. The following error messages can appear: The computation of the npde has failed for subject xx because the Cholesky decomposition of the covariance matrix of the simulated data could not be obtained. or The computation of the npde has failed for subject xx because the covariance matrix of the simulated data could not be inverted. followed by: This usually means that the covariance matrix is not positive-definite. This can be caused by simulations widely different from observations (in other words, a poor model). We suggest to plot a prediction interval from the simulated data to check whether the simulations are reasonable, and to consider prediction discrepancies. Prediction discrepancies will now be computed. In our experience, this usually happens when the model is so ill-conditioned that the matrices involved in the computation of the prediction distribution errors are singular, and mostly happens when the model predicts the data very poorly. A prediction interval (or Visual Predictive Check) can be plotted to check this. When \\(\\mathrm{npde}\\) cannot be computed, the program computes automatically \\(\\mathrm{pd}\\) even if the {calc.pd=F} option was used. The following graphs are plotted using \\(\\mathrm{pd}\\) instead of \\(\\mathrm{npde}\\) a quantile-quantile plot: plot of the \\(\\mathrm{pd}\\) versus the corresponding quantiles of a uniform distribution the line \\(y=x\\) is also drawn a histogram of the \\(\\mathrm{pd}\\) with the uniform density \\(\\mathcal{U}(0,1)\\) overlain a plot of the \\(\\mathrm{pd}\\) versus the independent variable X a plot of the \\(\\mathrm{pd}\\) versus \\(\\mathrm{ypred}\\) for these last two graphs, we plot the lines corresponding to \\(y=0\\) and to the 5% and 95% critical values (delimiting the 90% confidence interval in which we expect to find the bulk of the \\(\\mathrm{pd}\\)). In this case, approximated prediction intervals are not plotted by default, since the approximation (sampling from the standard gaussian distribution) neglects the correlation between the different \\(\\mathrm{pd}\\) in an individual, and this leads to substantially narrower prediction intervals when the number of data per subject is large. Prediction bands may be added by combining the option bands=TRUE with option approx.pi set to either TRUE for an approximated prediction interval (fast but rough) or FALSE for an approximated prediction interval (obtained using the simulated datasets), as in: x&lt;-dist.pred.sim(x) plot(x,bands=TRUE,approx.pi=TRUE) As seen here, requesting an exact (simulated) prediction interval requires first to compute the distribution of \\(\\mathrm{pd}\\) in the simulated dataset, using the function dist.pred.sim (by default and in the interest of time, this function computes only the distribution of the \\(\\mathrm{pd}\\), but if called with the additional argument calc.npde=TRUE the \\(\\mathrm{npde}\\) in the simulated dataset will also be included in the output, allowing the user to use approx.pi=TRUE for graphs including \\(\\mathrm{npde}\\)). 10.2 Functions in the npde package npde has been programmed using the S4 classes in R. S4 classes implement Object oriented programming (OOP) in R, allowing to construct modular pieces of code which can be used as black boxes for large systems. Most packages in the base library and many contributed packages use the former class system, called S3. However, S4 classes are a more traditional and complete object oriented system including type checking and multiple dispatching. S4 is implemented in the methods package in base R. More information on S4 classes and R packages can be found in tutorials on the Web. I used extensively the following manual (Genolini (2010)) (in French). The object returned by the npde() and autonpde() functions has the NpdeObject class, and both generic and specific methods have been defined for this class: print: the print function produces a summary of the object in a nice format show: this function is used invisibly by R when the name of the object is typed, and produces a short summary of the object (more details can be obtained by using the alternative showall() function summary: this function produces a summary of the object, and invisibly returns a list with a number of elements, which provides an alternative way to access elements of the class; the list contains the following elements: obsdat the data (a matrix with 3 columns, id=subject id, xobs=observed X, yobs=observed Y, plus if present in the data additional columns containing censored information, mdv, covariates, ) id subject id (first column in obsdat) observed x (second column in obsdat) y observed y (third column in obsdat) npde the computed \\(\\mathrm{npde}\\) pd the computed prediction discrepancies ploq the probability of being BQL for each observation (if computed) N number of subjects nrep number of simulations used in the computations ntot.obs total number of non-missing observations ypred predicted Y (the empirical mean of the simulated predicted distribution for each observation (\\(\\mathbb{E}_k(y^{sim(k)}_{ij})\\))) ycomp completed vector of observed y (includes the values that were imputed during the computation when BQL data are in the dataset) ydobs the decorrelated observed data \\(y_{ij}^*\\) ydsim the decorrelated simulated data \\(y^{sim(k)*}_{ij}\\) xerr an integer valued 0 if no error occurred during the computation or a positive number (1 or 2) depending on the error encountered, if an error occurred options options (can also be seen by using the print function) prefs graphical preferences (can also be seen by using the print function) plot: this produces plots of the different objects when called without any argument, the default four plots are produced the argument plot.type can be used to produce different plots the argument all plots can be tweaked to add titles, change colours,, (see section 8) \\([\\) function: the get function, used to access the value of the slots in an object \\([&lt;\\)-: function: the set function, used to replace the value of the slots in an object gof.test: goodness-of-fit tests on the distribution of npde (or pd) Examples of calls to these functions are given in the corresponding man pages and in the documentation (section {sec:exampletheo}). References "],["references.html", "11 References", " 11 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
